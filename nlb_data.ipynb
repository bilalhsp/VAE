{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the environment...!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/neurallatents/nlb_tools.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/bilalhsp/VAE.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git lfs install\n",
    "!git lfs pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from nlb_tools.evaluation import evaluate\n",
    "from nlb_tools.nwb_interface import NWBDataset\n",
    "from nlb_tools.make_tensors import make_train_input_tensors, make_eval_input_tensors\n",
    "from nlb_tools.make_tensors import make_eval_target_tensors\n",
    "from nlb_tools.make_tensors import save_to_h5\n",
    "import yaml\n",
    "import numpy as np\n",
    "import model\n",
    "import trainers\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading 'MC_Maze_Large' and pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Results for MC_Maze_Large\n",
    "############################\n",
    "# Loading the dataset...!\n",
    "with open('./config.yaml', 'r') as f:\n",
    "    manifest = yaml.load(f)#, Loader=yaml.FullLoader)\n",
    "\n",
    "hyper_param = manifest['hyper_param']\n",
    "model_param = manifest['large']\n",
    "results_dir = model_param['results_dir']\n",
    "\n",
    "print(\"-------Large Dataset---------\")\n",
    "print(\"Loading the dataset...!\")\n",
    "dataset = NWBDataset(fpath=model_param['data_dir'])\n",
    "dataset.resample(5)\n",
    "train_dict = make_train_input_tensors(dataset=dataset, \n",
    "            dataset_name=model_param['dataset_name'], \n",
    "            # trial_split='train', \n",
    "            trial_split=['train', 'val'], #for Test phase\n",
    "            save_file=False, \n",
    "            include_forward_pred=True)\n",
    "\n",
    "eval_dict = make_eval_input_tensors(dataset=dataset,\n",
    "            dataset_name=model_param['dataset_name'],\n",
    "            # trial_split='val', \n",
    "            trial_split='test',# for Test phase\n",
    "            save_file=False)\n",
    "\n",
    "training_input = torch.tensor(train_dict['train_spikes_heldin'], device=device, dtype=torch.float32)\n",
    "eval_input = torch.tensor(eval_dict['eval_spikes_heldin'], device=device, dtype=torch.float32)\n",
    "\n",
    "\n",
    "training_input = torch.tensor(\n",
    "    np.concatenate([\n",
    "        train_dict['train_spikes_heldin'], \n",
    "        np.zeros(train_dict['train_spikes_heldin_forward'].shape), # zeroed inputs for forecasting\n",
    "    ], axis=1), device=device, dtype=torch.float32)\n",
    "\n",
    "eval_input = torch.tensor(\n",
    "    np.concatenate([\n",
    "        eval_dict['eval_spikes_heldin'],\n",
    "        np.zeros((\n",
    "            eval_dict['eval_spikes_heldin'].shape[0],\n",
    "            train_dict['train_spikes_heldin_forward'].shape[1],\n",
    "            eval_dict['eval_spikes_heldin'].shape[2]\n",
    "        )),\n",
    "    ], axis=1), device=device, dtype=torch.float32)\n",
    "\n",
    "#Loading the pre-trained model...!\n",
    "vae = model.lstm_ae(hyper_param, model_param)\n",
    "trainer = trainers.VAE_trainer(vae,results_dir, hyper_param)\n",
    "\n",
    "epoch = trainer.load_checkpoint()\n",
    "print(f\"Loaded model was trained for {epoch} epochs\")\n",
    "\n",
    "# Get predictions from the model...!\n",
    "trainer.model.eval()\n",
    "training_predictions_large = trainer.model.predict(training_input).cpu().detach().numpy()\n",
    "eval_predictions_large = trainer.model.predict(eval_input).cpu().detach().numpy()\n",
    "\n",
    "#Prepare the submission dict...!\n",
    "tlen_large = train_dict['train_spikes_heldin'].shape[1]\n",
    "num_heldin_large = train_dict['train_spikes_heldin'].shape[2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading 'MC_Maze_Medium', pretrained model and getting predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Results for MC_Maze_Medium\n",
    "############################\n",
    "# Loading the dataset...!\n",
    "with open('./config.yaml', 'r') as f:\n",
    "    manifest = yaml.load(f)#, Loader=yaml.FullLoader)\n",
    "\n",
    "hyper_param = manifest['hyper_param']\n",
    "model_param = manifest['medium']\n",
    "results_dir = model_param['results_dir']\n",
    "\n",
    "print(\"-------Medium Dataset---------\")\n",
    "print(\"Loading the dataset...!\")\n",
    "dataset = NWBDataset(fpath=model_param['data_dir'])\n",
    "dataset.resample(5)\n",
    "train_dict = make_train_input_tensors(dataset=dataset, \n",
    "            dataset_name=model_param['dataset_name'], \n",
    "            # trial_split='train', \n",
    "            trial_split=['train', 'val'], #for Test phase\n",
    "            save_file=False, \n",
    "            include_forward_pred=True)\n",
    "\n",
    "eval_dict = make_eval_input_tensors(dataset=dataset,\n",
    "            dataset_name=model_param['dataset_name'],\n",
    "            # trial_split='val', \n",
    "            trial_split='test',# for Test phase\n",
    "            save_file=False)\n",
    "\n",
    "training_input = torch.tensor(train_dict['train_spikes_heldin'], device=device, dtype=torch.float32)\n",
    "eval_input = torch.tensor(eval_dict['eval_spikes_heldin'], device=device, dtype=torch.float32)\n",
    "\n",
    "\n",
    "training_input = torch.tensor(\n",
    "    np.concatenate([\n",
    "        train_dict['train_spikes_heldin'], \n",
    "        np.zeros(train_dict['train_spikes_heldin_forward'].shape), # zeroed inputs for forecasting\n",
    "    ], axis=1), device=device, dtype=torch.float32)\n",
    "\n",
    "eval_input = torch.tensor(\n",
    "    np.concatenate([\n",
    "        eval_dict['eval_spikes_heldin'],\n",
    "        np.zeros((\n",
    "            eval_dict['eval_spikes_heldin'].shape[0],\n",
    "            train_dict['train_spikes_heldin_forward'].shape[1],\n",
    "            eval_dict['eval_spikes_heldin'].shape[2]\n",
    "        )),\n",
    "    ], axis=1), device=device, dtype=torch.float32)\n",
    "\n",
    "#Loading the pre-trained model...!\n",
    "vae = model.lstm_ae(hyper_param, model_param)\n",
    "trainer = trainers.VAE_trainer(vae,results_dir, hyper_param)\n",
    "\n",
    "epoch = trainer.load_checkpoint()\n",
    "print(f\"Loaded model was trained for {epoch} epochs\")\n",
    "\n",
    "# Get predictions from the model...!\n",
    "trainer.model.eval()\n",
    "training_predictions_medium = trainer.model.predict(training_input).cpu().detach().numpy()\n",
    "eval_predictions_medium = trainer.model.predict(eval_input).cpu().detach().numpy()\n",
    "\n",
    "#Prepare the submission dict...!\n",
    "tlen_medium = train_dict['train_spikes_heldin'].shape[1]\n",
    "num_heldin_medium = train_dict['train_spikes_heldin'].shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading 'MC_Maze_Small', pretrained model and getting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Results for MC_Maze_small\n",
    "############################\n",
    "# Loading the dataset...!\n",
    "with open('./config.yaml', 'r') as f:\n",
    "    manifest = yaml.load(f)#, Loader=yaml.FullLoader)\n",
    "\n",
    "hyper_param = manifest['hyper_param']\n",
    "model_param = manifest['small']\n",
    "results_dir = model_param['results_dir']\n",
    "\n",
    "print(\"-------Small Dataset---------\")\n",
    "print(\"Loading the dataset...!\")\n",
    "dataset = NWBDataset(fpath=model_param['data_dir'])\n",
    "dataset.resample(5)\n",
    "train_dict = make_train_input_tensors(dataset=dataset, \n",
    "            dataset_name=model_param['dataset_name'], \n",
    "            # trial_split='train', \n",
    "            trial_split=['train', 'val'], #for Test phase\n",
    "            save_file=False, \n",
    "            include_forward_pred=True)\n",
    "\n",
    "eval_dict = make_eval_input_tensors(dataset=dataset,\n",
    "            dataset_name=model_param['dataset_name'],\n",
    "            # trial_split='val', \n",
    "            trial_split='test',# for Test phase\n",
    "            save_file=False)\n",
    "\n",
    "training_input = torch.tensor(train_dict['train_spikes_heldin'], device=device, dtype=torch.float32)\n",
    "eval_input = torch.tensor(eval_dict['eval_spikes_heldin'], device=device, dtype=torch.float32)\n",
    "\n",
    "\n",
    "training_input = torch.tensor(\n",
    "    np.concatenate([\n",
    "        train_dict['train_spikes_heldin'], \n",
    "        np.zeros(train_dict['train_spikes_heldin_forward'].shape), # zeroed inputs for forecasting\n",
    "    ], axis=1), device=device, dtype=torch.float32)\n",
    "\n",
    "eval_input = torch.tensor(\n",
    "    np.concatenate([\n",
    "        eval_dict['eval_spikes_heldin'],\n",
    "        np.zeros((\n",
    "            eval_dict['eval_spikes_heldin'].shape[0],\n",
    "            train_dict['train_spikes_heldin_forward'].shape[1],\n",
    "            eval_dict['eval_spikes_heldin'].shape[2]\n",
    "        )),\n",
    "    ], axis=1), device=device, dtype=torch.float32)\n",
    "\n",
    "#Loading the pre-trained model...!\n",
    "vae = model.lstm_ae(hyper_param, model_param)\n",
    "trainer = trainers.VAE_trainer(vae,results_dir, hyper_param)\n",
    "\n",
    "epoch = trainer.load_checkpoint()\n",
    "print(f\"Loaded model was trained for {epoch} epochs\")\n",
    "\n",
    "# Get predictions from the model...!\n",
    "trainer.model.eval()\n",
    "training_predictions_small = trainer.model.predict(training_input).cpu().detach().numpy()\n",
    "eval_predictions_small = trainer.model.predict(eval_input).cpu().detach().numpy()\n",
    "\n",
    "#Prepare the submission dict...!\n",
    "tlen_small = train_dict['train_spikes_heldin'].shape[1]\n",
    "num_heldin_small = train_dict['train_spikes_heldin'].shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the submission dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combining results...!\n",
    "print(\"Combining all results...!\")\n",
    "\n",
    "submission = {\n",
    "    'mc_maze_large': {\n",
    "        'train_rates_heldin': training_predictions_large[:, :tlen_large, :num_heldin_large],\n",
    "        'train_rates_heldout': training_predictions_large[:, :tlen_large, num_heldin_large:],\n",
    "        'eval_rates_heldin': eval_predictions_large[:, :tlen_large, :num_heldin_large],\n",
    "        'eval_rates_heldout': eval_predictions_large[:, :tlen_large, num_heldin_large:],\n",
    "        'eval_rates_heldin_forward': eval_predictions_large[:, tlen_large:, :num_heldin_large],\n",
    "        'eval_rates_heldout_forward': eval_predictions_large[:, tlen_large:, num_heldin_large:]\n",
    "    },\n",
    "    'mc_maze_medium': {\n",
    "        'train_rates_heldin': training_predictions_medium[:, :tlen_medium, :num_heldin_medium],\n",
    "        'train_rates_heldout': training_predictions_medium[:, :tlen_medium, num_heldin_medium:],\n",
    "        'eval_rates_heldin': eval_predictions_medium[:, :tlen_medium, :num_heldin_medium],\n",
    "        'eval_rates_heldout': eval_predictions_medium[:, :tlen_medium, num_heldin_medium:],\n",
    "        'eval_rates_heldin_forward': eval_predictions_medium[:, tlen_medium:, :num_heldin_medium],\n",
    "        'eval_rates_heldout_forward': eval_predictions_medium[:, tlen_medium:, num_heldin_medium:]\n",
    "    },\n",
    "    'mc_maze_small': {\n",
    "        'train_rates_heldin': training_predictions_small[:, :tlen_small, :num_heldin_small],\n",
    "        'train_rates_heldout': training_predictions_small[:, :tlen_small, num_heldin_small:],\n",
    "        'eval_rates_heldin': eval_predictions_small[:, :tlen_small, :num_heldin_small],\n",
    "        'eval_rates_heldout': eval_predictions_small[:, :tlen_small, num_heldin_small:],\n",
    "        'eval_rates_heldin_forward': eval_predictions_small[:, tlen_small:, :num_heldin_small],\n",
    "        'eval_rates_heldout_forward': eval_predictions_small[:, tlen_small:, num_heldin_small:]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### saving the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the submission results... use 'putput.out'\n",
    "print(\"Saving the submission file...!\")\n",
    "save_to_h5(submission, './results/submission.h5')\n",
    "print(\"Done...!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting results to 'evalai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install evalai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!evalai set_token eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ0b2tlbl90eXBlIjoicmVmcmVzaCIsImV4cCI6MTY4MjMyMTk3NiwianRpIjoiNTIwZGQ4N2RlMWFhNDNhMDk0Njc0ZGQxZDZiNjhjYjAiLCJ1c2VyX2lkIjoyMDA2M30.mb9PB7eid_Jhwe6X7nFhqhjYY6Vvzzb3xZW8-ZFS6CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!evalai challenge 1256 phase 2540 submit --file submission.h5"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
